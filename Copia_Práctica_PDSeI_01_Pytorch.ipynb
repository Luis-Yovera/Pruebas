{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luis-Yovera/Pruebas/blob/main/Copia_Pr%C3%A1ctica_PDSeI_01_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "-sfd5y_LexZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalaciones"
      ],
      "metadata": {
        "id": "tQGP2l2Ee2zU"
      }
    },
    {
      "metadata": {
        "id": "PtKvmZx-WmUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe5e9f4-f4ab-436c-d1b3-4c43de9375d6"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision #Conjuntos de datasets predefinidos y populares como CIFAR10, ImageNet, y COCO. facilitan el procesamiento y la manipulación de imágenes antes de entrenar modelos."
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar dependencias"
      ],
      "metadata": {
        "id": "3dr3HMvje_kV"
      }
    },
    {
      "metadata": {
        "id": "bGU6NwlsXFSt"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir Hiperparámetros"
      ],
      "metadata": {
        "id": "RbUo8FmkfFB1"
      }
    },
    {
      "metadata": {
        "id": "_bNfVLRUYqZA"
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 256  # Aumentado de 128 a 256\n",
        "num_classes = 10\n",
        "num_epochs = 20  # Aumentado de 5 a 20\n",
        "batch_size = 64  # Ajustado de 100 a 64\n",
        "lr = 5e-3  # Aumentado de 1e-3 a 5e-3"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargando la base de datos mnist"
      ],
      "metadata": {
        "id": "DM48UlJ9gMOE"
      }
    },
    {
      "metadata": {
        "id": "lCsBCXMwbpH5"
      },
      "cell_type": "code",
      "source": [
        "train_data = dsets.FashionMNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)  #Contiene el conjunto de imágenes y etiquetas del conjunto de entrenamiento\n",
        "                                                                              #  Contiene imágenes de prendas de ropa  //   28x28 píxeles\n",
        "test_data = dsets.FashionMNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor()) #Contiene el conjunto de imágenes y etiquetas del conjunto de prueba"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leyendo la data"
      ],
      "metadata": {
        "id": "WpMOKBJkhisv"
      }
    },
    {
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "cell_type": "code",
      "source": [
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)            #Es un DataLoader que gestiona los datos de entrenamiento, dividiéndolos en lotes de tamaño batch_size y barajando las muestras aleatoriamente para cada época.\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size,\n",
        "                                      shuffle = False)                  # Es Es un DataLoader que gestiona los datos de prueba, también dividiéndolos en lotes de tamaño batch_size, pero sin barajar los datos."
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir modelo"
      ],
      "metadata": {
        "id": "jhaazXo-h9-v"
      }
    },
    {
      "metadata": {
        "id": "fL-YXTvghaz_"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.drop = nn.Dropout(0.1) # Mientras más bajo sea, el modelo podrá retener ayor información\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.drop(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instancia del modelo"
      ],
      "metadata": {
        "id": "uQdjiXCeiNiu"
      }
    },
    {
      "metadata": {
        "id": "-3EPEqbjjfAT"
      },
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, num_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilación"
      ],
      "metadata": {
        "id": "QNgkx4xtipMA"
      }
    },
    {
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "KD3x_O7si_zS"
      }
    },
    {
      "metadata": {
        "id": "u75Xa5VckuTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1c5bfd-8938-4658-9b27-8ffc6ae504a1"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_gen):\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print('Epoca [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "              % (epoch + 1, num_epochs, i + 1, len(train_data) // batch_size, loss.item()))\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca [1/20], Step [100/937], Loss: 0.6702\n",
            "Epoca [1/20], Step [200/937], Loss: 0.4661\n",
            "Epoca [1/20], Step [300/937], Loss: 0.4544\n",
            "Epoca [1/20], Step [400/937], Loss: 0.6720\n",
            "Epoca [1/20], Step [500/937], Loss: 0.3078\n",
            "Epoca [1/20], Step [600/937], Loss: 0.4326\n",
            "Epoca [1/20], Step [700/937], Loss: 0.4129\n",
            "Epoca [1/20], Step [800/937], Loss: 0.5776\n",
            "Epoca [1/20], Step [900/937], Loss: 0.7622\n",
            "Epoca [2/20], Step [100/937], Loss: 0.3630\n",
            "Epoca [2/20], Step [200/937], Loss: 0.3823\n",
            "Epoca [2/20], Step [300/937], Loss: 0.3741\n",
            "Epoca [2/20], Step [400/937], Loss: 0.3118\n",
            "Epoca [2/20], Step [500/937], Loss: 0.3433\n",
            "Epoca [2/20], Step [600/937], Loss: 0.3487\n",
            "Epoca [2/20], Step [700/937], Loss: 0.4533\n",
            "Epoca [2/20], Step [800/937], Loss: 0.5578\n",
            "Epoca [2/20], Step [900/937], Loss: 0.2125\n",
            "Epoca [3/20], Step [100/937], Loss: 0.2587\n",
            "Epoca [3/20], Step [200/937], Loss: 0.6148\n",
            "Epoca [3/20], Step [300/937], Loss: 0.3839\n",
            "Epoca [3/20], Step [400/937], Loss: 0.2677\n",
            "Epoca [3/20], Step [500/937], Loss: 0.2736\n",
            "Epoca [3/20], Step [600/937], Loss: 0.3787\n",
            "Epoca [3/20], Step [700/937], Loss: 0.4644\n",
            "Epoca [3/20], Step [800/937], Loss: 0.2740\n",
            "Epoca [3/20], Step [900/937], Loss: 0.5384\n",
            "Epoca [4/20], Step [100/937], Loss: 0.3588\n",
            "Epoca [4/20], Step [200/937], Loss: 0.2613\n",
            "Epoca [4/20], Step [300/937], Loss: 0.5061\n",
            "Epoca [4/20], Step [400/937], Loss: 0.2055\n",
            "Epoca [4/20], Step [500/937], Loss: 0.5674\n",
            "Epoca [4/20], Step [600/937], Loss: 0.3271\n",
            "Epoca [4/20], Step [700/937], Loss: 0.2738\n",
            "Epoca [4/20], Step [800/937], Loss: 0.6036\n",
            "Epoca [4/20], Step [900/937], Loss: 0.4103\n",
            "Epoca [5/20], Step [100/937], Loss: 0.4772\n",
            "Epoca [5/20], Step [200/937], Loss: 0.3146\n",
            "Epoca [5/20], Step [300/937], Loss: 0.3354\n",
            "Epoca [5/20], Step [400/937], Loss: 0.3384\n",
            "Epoca [5/20], Step [500/937], Loss: 0.3989\n",
            "Epoca [5/20], Step [600/937], Loss: 0.3865\n",
            "Epoca [5/20], Step [700/937], Loss: 0.5148\n",
            "Epoca [5/20], Step [800/937], Loss: 0.1518\n",
            "Epoca [5/20], Step [900/937], Loss: 0.3584\n",
            "Epoca [6/20], Step [100/937], Loss: 0.2776\n",
            "Epoca [6/20], Step [200/937], Loss: 0.3912\n",
            "Epoca [6/20], Step [300/937], Loss: 0.5438\n",
            "Epoca [6/20], Step [400/937], Loss: 0.3403\n",
            "Epoca [6/20], Step [500/937], Loss: 0.2991\n",
            "Epoca [6/20], Step [600/937], Loss: 0.2998\n",
            "Epoca [6/20], Step [700/937], Loss: 0.2961\n",
            "Epoca [6/20], Step [800/937], Loss: 0.3828\n",
            "Epoca [6/20], Step [900/937], Loss: 0.2695\n",
            "Epoca [7/20], Step [100/937], Loss: 0.1863\n",
            "Epoca [7/20], Step [200/937], Loss: 0.3339\n",
            "Epoca [7/20], Step [300/937], Loss: 0.2739\n",
            "Epoca [7/20], Step [400/937], Loss: 0.4019\n",
            "Epoca [7/20], Step [500/937], Loss: 0.2853\n",
            "Epoca [7/20], Step [600/937], Loss: 0.1428\n",
            "Epoca [7/20], Step [700/937], Loss: 0.3036\n",
            "Epoca [7/20], Step [800/937], Loss: 0.4895\n",
            "Epoca [7/20], Step [900/937], Loss: 0.1806\n",
            "Epoca [8/20], Step [100/937], Loss: 0.1464\n",
            "Epoca [8/20], Step [200/937], Loss: 0.3517\n",
            "Epoca [8/20], Step [300/937], Loss: 0.4928\n",
            "Epoca [8/20], Step [400/937], Loss: 0.2810\n",
            "Epoca [8/20], Step [500/937], Loss: 0.3708\n",
            "Epoca [8/20], Step [600/937], Loss: 0.2801\n",
            "Epoca [8/20], Step [700/937], Loss: 0.2867\n",
            "Epoca [8/20], Step [800/937], Loss: 0.2433\n",
            "Epoca [8/20], Step [900/937], Loss: 0.3083\n",
            "Epoca [9/20], Step [100/937], Loss: 0.5335\n",
            "Epoca [9/20], Step [200/937], Loss: 0.1967\n",
            "Epoca [9/20], Step [300/937], Loss: 0.1697\n",
            "Epoca [9/20], Step [400/937], Loss: 0.5278\n",
            "Epoca [9/20], Step [500/937], Loss: 0.2113\n",
            "Epoca [9/20], Step [600/937], Loss: 0.2520\n",
            "Epoca [9/20], Step [700/937], Loss: 0.3260\n",
            "Epoca [9/20], Step [800/937], Loss: 0.2636\n",
            "Epoca [9/20], Step [900/937], Loss: 0.3642\n",
            "Epoca [10/20], Step [100/937], Loss: 0.2773\n",
            "Epoca [10/20], Step [200/937], Loss: 0.3599\n",
            "Epoca [10/20], Step [300/937], Loss: 0.3793\n",
            "Epoca [10/20], Step [400/937], Loss: 0.3909\n",
            "Epoca [10/20], Step [500/937], Loss: 0.3328\n",
            "Epoca [10/20], Step [600/937], Loss: 0.3848\n",
            "Epoca [10/20], Step [700/937], Loss: 0.3100\n",
            "Epoca [10/20], Step [800/937], Loss: 0.3861\n",
            "Epoca [10/20], Step [900/937], Loss: 0.2753\n",
            "Epoca [11/20], Step [100/937], Loss: 0.4090\n",
            "Epoca [11/20], Step [200/937], Loss: 0.2224\n",
            "Epoca [11/20], Step [300/937], Loss: 0.2676\n",
            "Epoca [11/20], Step [400/937], Loss: 0.3425\n",
            "Epoca [11/20], Step [500/937], Loss: 0.3376\n",
            "Epoca [11/20], Step [600/937], Loss: 0.2580\n",
            "Epoca [11/20], Step [700/937], Loss: 0.1203\n",
            "Epoca [11/20], Step [800/937], Loss: 0.4761\n",
            "Epoca [11/20], Step [900/937], Loss: 0.2342\n",
            "Epoca [12/20], Step [100/937], Loss: 0.2696\n",
            "Epoca [12/20], Step [200/937], Loss: 0.2730\n",
            "Epoca [12/20], Step [300/937], Loss: 0.3750\n",
            "Epoca [12/20], Step [400/937], Loss: 0.3095\n",
            "Epoca [12/20], Step [500/937], Loss: 0.2923\n",
            "Epoca [12/20], Step [600/937], Loss: 0.3064\n",
            "Epoca [12/20], Step [700/937], Loss: 0.1562\n",
            "Epoca [12/20], Step [800/937], Loss: 0.3650\n",
            "Epoca [12/20], Step [900/937], Loss: 0.2568\n",
            "Epoca [13/20], Step [100/937], Loss: 0.2793\n",
            "Epoca [13/20], Step [200/937], Loss: 0.2719\n",
            "Epoca [13/20], Step [300/937], Loss: 0.3376\n",
            "Epoca [13/20], Step [400/937], Loss: 0.3008\n",
            "Epoca [13/20], Step [500/937], Loss: 0.3410\n",
            "Epoca [13/20], Step [600/937], Loss: 0.4585\n",
            "Epoca [13/20], Step [700/937], Loss: 0.4045\n",
            "Epoca [13/20], Step [800/937], Loss: 0.2128\n",
            "Epoca [13/20], Step [900/937], Loss: 0.2577\n",
            "Epoca [14/20], Step [100/937], Loss: 0.3454\n",
            "Epoca [14/20], Step [200/937], Loss: 0.4138\n",
            "Epoca [14/20], Step [300/937], Loss: 0.6115\n",
            "Epoca [14/20], Step [400/937], Loss: 0.5136\n",
            "Epoca [14/20], Step [500/937], Loss: 0.1345\n",
            "Epoca [14/20], Step [600/937], Loss: 0.1949\n",
            "Epoca [14/20], Step [700/937], Loss: 0.3010\n",
            "Epoca [14/20], Step [800/937], Loss: 0.2635\n",
            "Epoca [14/20], Step [900/937], Loss: 0.3080\n",
            "Epoca [15/20], Step [100/937], Loss: 0.2351\n",
            "Epoca [15/20], Step [200/937], Loss: 0.3705\n",
            "Epoca [15/20], Step [300/937], Loss: 0.3628\n",
            "Epoca [15/20], Step [400/937], Loss: 0.3574\n",
            "Epoca [15/20], Step [500/937], Loss: 0.2894\n",
            "Epoca [15/20], Step [600/937], Loss: 0.1481\n",
            "Epoca [15/20], Step [700/937], Loss: 0.3229\n",
            "Epoca [15/20], Step [800/937], Loss: 0.3508\n",
            "Epoca [15/20], Step [900/937], Loss: 0.2835\n",
            "Epoca [16/20], Step [100/937], Loss: 0.4522\n",
            "Epoca [16/20], Step [200/937], Loss: 0.2321\n",
            "Epoca [16/20], Step [300/937], Loss: 0.2242\n",
            "Epoca [16/20], Step [400/937], Loss: 0.3913\n",
            "Epoca [16/20], Step [500/937], Loss: 0.2882\n",
            "Epoca [16/20], Step [600/937], Loss: 0.2852\n",
            "Epoca [16/20], Step [700/937], Loss: 0.1752\n",
            "Epoca [16/20], Step [800/937], Loss: 0.2860\n",
            "Epoca [16/20], Step [900/937], Loss: 0.3917\n",
            "Epoca [17/20], Step [100/937], Loss: 0.1996\n",
            "Epoca [17/20], Step [200/937], Loss: 0.2971\n",
            "Epoca [17/20], Step [300/937], Loss: 0.4246\n",
            "Epoca [17/20], Step [400/937], Loss: 0.3441\n",
            "Epoca [17/20], Step [500/937], Loss: 0.2301\n",
            "Epoca [17/20], Step [600/937], Loss: 0.5726\n",
            "Epoca [17/20], Step [700/937], Loss: 0.3356\n",
            "Epoca [17/20], Step [800/937], Loss: 0.1817\n",
            "Epoca [17/20], Step [900/937], Loss: 0.2879\n",
            "Epoca [18/20], Step [100/937], Loss: 0.3688\n",
            "Epoca [18/20], Step [200/937], Loss: 0.2017\n",
            "Epoca [18/20], Step [300/937], Loss: 0.2926\n",
            "Epoca [18/20], Step [400/937], Loss: 0.1997\n",
            "Epoca [18/20], Step [500/937], Loss: 0.3056\n",
            "Epoca [18/20], Step [600/937], Loss: 0.2226\n",
            "Epoca [18/20], Step [700/937], Loss: 0.1851\n",
            "Epoca [18/20], Step [800/937], Loss: 0.2389\n",
            "Epoca [18/20], Step [900/937], Loss: 0.1920\n",
            "Epoca [19/20], Step [100/937], Loss: 0.3519\n",
            "Epoca [19/20], Step [200/937], Loss: 0.2856\n",
            "Epoca [19/20], Step [300/937], Loss: 0.3261\n",
            "Epoca [19/20], Step [400/937], Loss: 0.1978\n",
            "Epoca [19/20], Step [500/937], Loss: 0.2705\n",
            "Epoca [19/20], Step [600/937], Loss: 0.3681\n",
            "Epoca [19/20], Step [700/937], Loss: 0.5245\n",
            "Epoca [19/20], Step [800/937], Loss: 0.3289\n",
            "Epoca [19/20], Step [900/937], Loss: 0.2284\n",
            "Epoca [20/20], Step [100/937], Loss: 0.3257\n",
            "Epoca [20/20], Step [200/937], Loss: 0.3452\n",
            "Epoca [20/20], Step [300/937], Loss: 0.1556\n",
            "Epoca [20/20], Step [400/937], Loss: 0.2641\n",
            "Epoca [20/20], Step [500/937], Loss: 0.2079\n",
            "Epoca [20/20], Step [600/937], Loss: 0.2124\n",
            "Epoca [20/20], Step [700/937], Loss: 0.4552\n",
            "Epoca [20/20], Step [800/937], Loss: 0.2782\n",
            "Epoca [20/20], Step [900/937], Loss: 0.2048\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DTPvMW5jHB9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d772f994-7245-4e89-c5df-fb890d44aa97"
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_gen:\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    output = net(images)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "\n",
        "print('Accuracy: %.3f %%' % (100 * correct / (total + 1)))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.931 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1NojkXHle9d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}